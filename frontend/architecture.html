<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Architecture | O&G RAG Assistant</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <!-- Navigation -->
    <nav class="navbar">
        <div class="container">
            <div class="nav-brand">
                <h1>ğŸ›¢ï¸ O&G RAG Assistant</h1>
            </div>
            <ul class="nav-links">
                <li><a href="index.html">Query</a></li>
                <li><a href="architecture.html" class="active">Architecture</a></li>
                <li><a href="corpus.html">Corpus</a></li>
                <li><a href="https://github.com/keithcockerham/og-rag" target="_blank">GitHub</a></li>
            </ul>
        </div>
    </nav>

    <!-- Hero Section -->
    <section class="hero">
        <div class="container">
            <div class="hero-content">
                <h2>System Architecture</h2>
                <p class="subtitle">End-to-end RAG pipeline from document ingestion to answer generation</p>
            </div>
        </div>
    </section>

    <!-- Architecture Diagram -->
    <section class="results-preview">
        <div class="container">
            <h2>High-Level Architecture</h2>
            <div class="architecture-diagram">
                <pre class="diagram-ascii">
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                            USER INTERFACE                                    â”‚
â”‚                         (GitHub Pages)                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Query Input   â”‚  â”‚  Settings    â”‚  â”‚  Results + Source Citations     â”‚   â”‚
â”‚  â”‚               â”‚  â”‚  â€¢ top_k     â”‚  â”‚  â€¢ Generated Answer             â”‚   â”‚
â”‚  â”‚  "What is     â”‚  â”‚  â€¢ min_score â”‚  â”‚  â€¢ Expandable Sources           â”‚   â”‚
â”‚  â”‚   gas lock?"  â”‚  â”‚              â”‚  â”‚  â€¢ Relevance Scores             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚ HTTPS POST /api/query
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          AZURE FUNCTIONS                                     â”‚
â”‚                        (Serverless API)                                      â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                         Query Processing                             â”‚    â”‚
â”‚  â”‚                                                                      â”‚    â”‚
â”‚  â”‚   1. Validate input                                                  â”‚    â”‚
â”‚  â”‚   2. Load embedding model (cached)                                   â”‚    â”‚
â”‚  â”‚   3. Embed query â†’ 768-dim vector                                    â”‚    â”‚
â”‚  â”‚   4. Search Pinecone                                                 â”‚    â”‚
â”‚  â”‚   5. Filter by min_score                                             â”‚    â”‚
â”‚  â”‚   6. Build prompt with context                                       â”‚    â”‚
â”‚  â”‚   7. Call Claude API                                                 â”‚    â”‚
â”‚  â”‚   8. Return answer + sources                                         â”‚    â”‚
â”‚  â”‚                                                                      â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                              â”‚
â”‚  Endpoints:  /api/query  â”‚  /api/health  â”‚  /api/stats                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚                                     â”‚
               â–¼                                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        PINECONE              â”‚      â”‚      ANTHROPIC API           â”‚
â”‚     Vector Database          â”‚      â”‚     (Claude Sonnet 4)        â”‚
â”‚                              â”‚      â”‚                              â”‚
â”‚  â€¢ 66,497 vectors            â”‚      â”‚  â€¢ System prompt with        â”‚
â”‚  â€¢ 768 dimensions            â”‚      â”‚    domain expertise          â”‚
â”‚  â€¢ Cosine similarity         â”‚      â”‚  â€¢ Context from retrieved    â”‚
â”‚  â€¢ Metadata filtering        â”‚      â”‚    sources                   â”‚
â”‚                              â”‚      â”‚  â€¢ Citation instructions     â”‚
â”‚  Index: og-rag               â”‚      â”‚  â€¢ 1024 max tokens           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                </pre>
            </div>
        </div>
    </section>

    <!-- Data Pipeline -->
    <section class="findings">
        <div class="container">
            <h2>Data Ingestion Pipeline</h2>
            <div class="architecture-diagram">
                <pre class="diagram-ascii">
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   SOURCE    â”‚    â”‚   SOURCE    â”‚    â”‚   SOURCE    â”‚    â”‚   SOURCE    â”‚
â”‚    BSEE     â”‚    â”‚   PHMSA     â”‚    â”‚    CSB      â”‚    â”‚   OSHA      â”‚
â”‚  585 PDFs   â”‚    â”‚   77 PDFs   â”‚    â”‚  185 PDFs   â”‚    â”‚   76 PDFs   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚                  â”‚                  â”‚                  â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                                   â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚     Web Scrapers         â”‚
                    â”‚                          â”‚
                    â”‚  â€¢ Rate limited          â”‚
                    â”‚  â€¢ Retry logic           â”‚
                    â”‚  â€¢ Deduplication         â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    PDF Text Extraction   â”‚
                    â”‚       (PyMuPDF)          â”‚
                    â”‚                          â”‚
                    â”‚  â€¢ OCR fallback          â”‚
                    â”‚  â€¢ Metadata extraction   â”‚
                    â”‚  â€¢ Source classification â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    Document Chunking     â”‚
                    â”‚                          â”‚
                    â”‚  â€¢ 1000 char chunks      â”‚
                    â”‚  â€¢ 200 char overlap      â”‚
                    â”‚  â€¢ Preserve boundaries   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Embedding Generation   â”‚
                    â”‚    (BGE-base-en-v1.5)    â”‚
                    â”‚                          â”‚
                    â”‚  â€¢ 768 dimensions        â”‚
                    â”‚  â€¢ Batch processing      â”‚
                    â”‚  â€¢ ~6.6M tokens total    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    Pinecone Ingestion    â”‚
                    â”‚                          â”‚
                    â”‚  â€¢ 66,497 vectors        â”‚
                    â”‚  â€¢ Metadata attached     â”‚
                    â”‚  â€¢ ~15 min upload        â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                </pre>
            </div>
        </div>
    </section>

    <!-- Component Details -->
    <section class="overview">
        <div class="container">
            <h2>Component Details</h2>
            <div class="overview-grid">
                <div class="overview-card">
                    <h3>ğŸ” Embedding Model</h3>
                    <p><strong>BAAI/bge-base-en-v1.5</strong></p>
                    <p>State-of-the-art dense retrieval model optimized for semantic similarity. Produces 768-dimensional vectors that capture meaning beyond keyword matching.</p>
                    <p class="tech-detail">Why BGE? Outperforms OpenAI ada-002 on technical content while running locally for lower latency and cost.</p>
                </div>
                <div class="overview-card">
                    <h3>ğŸ—„ï¸ Vector Database</h3>
                    <p><strong>Pinecone</strong></p>
                    <p>Managed vector database with millisecond query latency. Handles similarity search across 66K+ vectors with metadata filtering support.</p>
                    <p class="tech-detail">Cosine similarity metric. Supports filtering by source, doc_type, and other metadata fields.</p>
                </div>
                <div class="overview-card">
                    <h3>ğŸ¤– Language Model</h3>
                    <p><strong>Claude Sonnet 4</strong></p>
                    <p>Anthropic's latest model with strong instruction-following and reduced hallucination. Generates answers grounded in provided context.</p>
                    <p class="tech-detail">System prompt establishes O&G domain expertise and citation requirements.</p>
                </div>
                <div class="overview-card">
                    <h3>âš¡ API Backend</h3>
                    <p><strong>Azure Functions</strong></p>
                    <p>Serverless compute with automatic scaling. Consumption plan keeps costs minimal during low traffic.</p>
                    <p class="tech-detail">5-minute timeout configured for cold starts when loading embedding model (~400MB).</p>
                </div>
                <div class="overview-card">
                    <h3>ğŸ“„ Text Extraction</h3>
                    <p><strong>PyMuPDF (fitz)</strong></p>
                    <p>Fast, accurate PDF text extraction. Handles complex layouts from government documents and technical manuals.</p>
                    <p class="tech-detail">Fallback to OCR for scanned documents. Preserves reading order and structure.</p>
                </div>
                <div class="overview-card">
                    <h3>âœ‚ï¸ Chunking Strategy</h3>
                    <p><strong>1000 chars / 200 overlap</strong></p>
                    <p>Balances context completeness with retrieval precision. Overlap ensures concepts split across boundaries are still findable.</p>
                    <p class="tech-detail">Sentence-aware splitting when possible. Metadata preserved per chunk.</p>
                </div>
            </div>
        </div>
    </section>

    <!-- Query Flow Detail -->
    <section class="technical">
        <div class="container">
            <h2>Query Processing Flow</h2>
            <div class="flow-steps">
                <div class="flow-step">
                    <div class="step-number">1</div>
                    <div class="step-content">
                        <h4>Query Reception</h4>
                        <p>User submits question via web interface. Request includes query text, top_k (number of sources), and min_score threshold.</p>
                        <code>POST /api/query { "query": "...", "top_k": 10, "min_score": 0.7 }</code>
                    </div>
                </div>
                <div class="flow-step">
                    <div class="step-number">2</div>
                    <div class="step-content">
                        <h4>Query Embedding</h4>
                        <p>Question is converted to 768-dimensional vector using same BGE model used for corpus. This ensures query and documents are in the same semantic space.</p>
                        <code>vector = embed_model.encode(query)  # â†’ [0.023, -0.156, ...]</code>
                    </div>
                </div>
                <div class="flow-step">
                    <div class="step-number">3</div>
                    <div class="step-content">
                        <h4>Vector Search</h4>
                        <p>Pinecone finds most similar document chunks using cosine similarity. Returns top_k results with similarity scores and metadata.</p>
                        <code>results = index.query(vector=vector, top_k=10, include_metadata=True)</code>
                    </div>
                </div>
                <div class="flow-step">
                    <div class="step-number">4</div>
                    <div class="step-content">
                        <h4>Score Filtering</h4>
                        <p>Results below min_score threshold are filtered out. This removes marginally relevant content that might confuse the LLM.</p>
                        <code>contexts = [r for r in results if r.score >= 0.7]</code>
                    </div>
                </div>
                <div class="flow-step">
                    <div class="step-number">5</div>
                    <div class="step-content">
                        <h4>Prompt Assembly</h4>
                        <p>Retrieved chunks are formatted into structured XML with source metadata. System prompt establishes domain expertise and citation requirements.</p>
                        <code>&lt;source id="1" origin="BSEE" type="safety_alert"&gt;...&lt;/source&gt;</code>
                    </div>
                </div>
                <div class="flow-step">
                    <div class="step-number">6</div>
                    <div class="step-content">
                        <h4>Answer Generation</h4>
                        <p>Claude synthesizes answer from provided context, citing specific sources. Acknowledges limitations when information is incomplete.</p>
                        <code>response = claude.messages.create(model="claude-sonnet-4-20250514", ...)</code>
                    </div>
                </div>
                <div class="flow-step">
                    <div class="step-number">7</div>
                    <div class="step-content">
                        <h4>Response Delivery</h4>
                        <p>Answer returned with source citations. Frontend displays expandable source cards showing retrieved text and relevance scores.</p>
                        <code>{ "answer": "...", "sources": [{ "text": "...", "score": 0.85 }] }</code>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Performance -->
    <section class="findings">
        <div class="container">
            <h2>Performance Characteristics</h2>
            <div class="findings-grid">
                <div class="finding-card">
                    <div class="finding-icon">â±ï¸</div>
                    <h3>Latency</h3>
                    <p><strong>Cold Start:</strong> 10-15 seconds (embedding model load)</p>
                    <p><strong>Warm Query:</strong> 2-3 seconds total</p>
                    <p><strong>Retrieval:</strong> &lt;500ms</p>
                    <p><strong>Generation:</strong> 1-2 seconds</p>
                </div>
                <div class="finding-card">
                    <div class="finding-icon">ğŸ’°</div>
                    <h3>Cost</h3>
                    <p><strong>Pinecone:</strong> Free tier (100K vectors)</p>
                    <p><strong>Azure Functions:</strong> ~$0.20/1000 queries</p>
                    <p><strong>Claude API:</strong> ~$0.01-0.03/query</p>
                    <p><strong>Total:</strong> &lt;$0.05/query</p>
                </div>
                <div class="finding-card">
                    <div class="finding-icon">ğŸ“ˆ</div>
                    <h3>Scalability</h3>
                    <p><strong>Concurrent Users:</strong> Auto-scales with Azure Functions</p>
                    <p><strong>Corpus Size:</strong> Pinecone handles millions of vectors</p>
                    <p><strong>Bottleneck:</strong> Claude API rate limits</p>
                </div>
                <div class="finding-card">
                    <div class="finding-icon">ğŸ¯</div>
                    <h3>Quality</h3>
                    <p><strong>Retrieval Precision:</strong> ~85% relevant at top-5</p>
                    <p><strong>Answer Grounding:</strong> Citations in 90%+ responses</p>
                    <p><strong>Hallucination:</strong> Minimal with context constraints</p>
                </div>
            </div>
        </div>
    </section>

    <!-- Design Decisions -->
    <section class="overview">
        <div class="container">
            <h2>Key Design Decisions</h2>
            <div class="overview-grid">
                <div class="overview-card">
                    <h3>Why RAG over Fine-tuning?</h3>
                    <p>RAG provides verifiable sources, handles corpus updates without retraining, and works with any LLM. Fine-tuning would "bake in" knowledge without citationsâ€”problematic for regulated industries where provenance matters.</p>
                </div>
                <div class="overview-card">
                    <h3>Why BGE over OpenAI Embeddings?</h3>
                    <p>BGE-base runs locally (faster, no API calls), performs better on technical content in benchmarks, and reduces dependency on external services. 768 dimensions is sufficient for this corpus size.</p>
                </div>
                <div class="overview-card">
                    <h3>Why Serverless?</h3>
                    <p>Portfolio project with sporadic traffic. Consumption plan means near-zero cost when idle. Trade-off is cold start latencyâ€”acceptable for demo purposes.</p>
                </div>
            </div>
        </div>
    </section>

    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <p>Built by Keith | <a href="https://github.com/keithcockerham">GitHub</a> | <a href="https://linkedin.com/in/kcockerham">LinkedIn</a></p>
            <p>O&G RAG Assistant | Retrieval-Augmented Generation for Energy Domain</p>
        </div>
    </footer>

    <style>
        /* Additional styles for architecture page */
        .architecture-diagram {
            background: #1a202c;
            border-radius: 12px;
            padding: 2rem;
            overflow-x: auto;
            margin-top: 1rem;
        }
        
        .diagram-ascii {
            color: #38ef7d;
            font-family: 'Monaco', 'Menlo', 'Ubuntu Mono', monospace;
            font-size: 0.75rem;
            line-height: 1.4;
            white-space: pre;
            margin: 0;
        }
        
        .tech-detail {
            font-size: 0.85rem;
            color: var(--text-light);
            margin-top: 0.5rem;
            font-style: italic;
        }
        
        .flow-steps {
            max-width: 800px;
            margin: 0 auto;
        }
        
        .flow-step {
            display: flex;
            gap: 1.5rem;
            margin-bottom: 2rem;
            align-items: flex-start;
        }
        
        .step-number {
            width: 50px;
            height: 50px;
            background: linear-gradient(135deg, var(--primary-color) 0%, var(--secondary-color) 100%);
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            color: white;
            font-weight: 700;
            font-size: 1.25rem;
            flex-shrink: 0;
        }
        
        .step-content {
            flex: 1;
            background: white;
            padding: 1.5rem;
            border-radius: 12px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.08);
        }
        
        .step-content h4 {
            color: var(--primary-color);
            margin-bottom: 0.5rem;
        }
        
        .step-content p {
            color: var(--text-light);
            margin-bottom: 0.75rem;
        }
        
        .step-content code {
            display: block;
            background: #f1f5f9;
            padding: 0.75rem;
            border-radius: 6px;
            font-size: 0.85rem;
            color: var(--text-dark);
            overflow-x: auto;
        }
        
        @media (max-width: 768px) {
            .diagram-ascii {
                font-size: 0.5rem;
            }
            
            .flow-step {
                flex-direction: column;
                align-items: center;
                text-align: center;
            }
        }
    </style>
</body>
</html>
